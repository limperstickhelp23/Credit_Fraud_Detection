{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-e_9heLsAsx"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook was also used to keep track code that we wanted to use to preprocess or graph. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zcDoKIUKGL7"
      },
      "outputs": [],
      "source": [
        "#Do this to use imblearn\n",
        "!pip uninstall scikit-learn --yes\n",
        "!pip uninstall imblearn --yes\n",
        "!pip install scikit-learn==1.2.2\n",
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdl-BCGN6IZ1"
      },
      "outputs": [],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQQLYs6PC5EU"
      },
      "outputs": [],
      "source": [
        "!pip install feature-engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T504ma3sURu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from category_encoders import TargetEncoder\n",
        "from category_encoders import HashingEncoder\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, BaggingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from feature_engine.encoding import CountFrequencyEncoder, MeanEncoder, RareLabelEncoder, OrdinalEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm-kngHCtNTJ"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('fraud_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaYHUJ7HDpd2"
      },
      "outputs": [],
      "source": [
        "y = data[\"is_fraud\"]\n",
        "X = data.drop(['is_fraud'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is just an aggregation of the main preprocessing that was implemented on all models. Then for each specfic model we had more unique processing of the data. The code below as mentioned was taken from differnt kaggle codebases to allow us to preprocess quicker without having to type. This is already mentioned in the RF notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crhPxJiRt3oH",
        "outputId": "62c167c3-11fc-4978-c8ed-9c19fb2fac7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-132-ee95265836cb>:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_used[\"gender\"] = X_used[\"gender\"].replace({'M': 0, 'F': 1})\n"
          ]
        }
      ],
      "source": [
        "#Modify columns\n",
        "X_used = X.drop(['Unnamed: 0','street','city','state','cc_num', 'unix_time', 'trans_num'], axis=1)\n",
        "X_used[['date', 'time']] = X_used['trans_date_trans_time'].str.split(' ', expand=True)\n",
        "X_used[['day', 'month', 'year']] = X_used['date'].str.split('/', expand=True)\n",
        "X_used['time'] = X_used['time'].apply(lambda x: x.split(':')[0])\n",
        "X_used['dob'] = X_used['dob'].apply(lambda x: x.split('/')[-1])\n",
        "X_used[\"gender\"] = X_used[\"gender\"].replace({'M': 0, 'F': 1})\n",
        "X_used = X_used.drop(['trans_date_trans_time','date'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXgM3XAdGBCa"
      },
      "outputs": [],
      "source": [
        "print(X_used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9yjBjMPFhxY"
      },
      "outputs": [],
      "source": [
        "used_data = X_used.copy()\n",
        "used_data['is_fraud'] = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjY0MFHtF4m3"
      },
      "outputs": [],
      "source": [
        "print(used_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QYPYHy8Hs04"
      },
      "outputs": [],
      "source": [
        "features = used_data.select_dtypes(np.object_).columns\n",
        "cat_features = []\n",
        "for feature in features:\n",
        "    used_data[feature] = used_data[feature].astype('category')\n",
        "    cat_features.append(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3uC4YoID4FG"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(used_data.drop('is_fraud', axis = 1),\n",
        "                                                    used_data['is_fraud'],\n",
        "                                                    stratify = used_data['is_fraud'],\n",
        "                                                    test_size = 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuRYPZd2GlXn"
      },
      "outputs": [],
      "source": [
        "train_data = X_train.copy()\n",
        "train_data['is_fraud'] = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSSqYzcdGcJd"
      },
      "outputs": [],
      "source": [
        "#Show plot\n",
        "import matplotlib.pyplot as plt\n",
        "colors = [\"#0101DF\", \"#DF0101\"]\n",
        "sns.countplot(x='is_fraud', data=train_data, palette=colors)\n",
        "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K7YRZSmIxhL"
      },
      "outputs": [],
      "source": [
        "print(train_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7oe1A1sG9Rw"
      },
      "outputs": [],
      "source": [
        "target_encoder = TargetEncoder()\n",
        "train_data[cat_features] = target_encoder.fit_transform(train_data[cat_features], train_data[\"is_fraud\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2GHujD8HKhO"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6HtVlddjETu"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop('is_fraud',axis=1)\n",
        "y_train = train_data[\"is_fraud\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvqXAB7qQ_2t"
      },
      "outputs": [],
      "source": [
        "X_test[cat_features] = target_encoder.transform(X_test[cat_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBXFKjh7wZuE"
      },
      "outputs": [],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oNcW_0mgM41"
      },
      "outputs": [],
      "source": [
        "#print confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkcyvvm7hO9b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute ROC curve and ROC area for the positive class\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_ovs[:,1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Compute Precision-Recall curve and area for the positive class\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba_ovs[:,1])\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='red', lw=2, label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBS5N7Z-BafH"
      },
      "source": [
        "https://www.kaggle.com/code/eisgandar/oversampling-methods-on-unbalanced-datasets"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
